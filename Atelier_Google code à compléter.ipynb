{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y8byKSDweife"
   },
   "source": [
    "# Développer pour l'IA : computer vision avec Transfer Learning\n",
    "\n",
    "Atelier du 23 juillet 2019 Google Atelier Numérique\n",
    "\n",
    "Animé par [Romain Bardon](https://www.linkedin.com/in/romain-bardon/) (IAdvance) et [Nicolas Lecointe](https://www.linkedin.com/in/nicolaslecointe/) (Macaron Software)\n",
    "\n",
    "\n",
    "Ce que l'on va utiliser : \n",
    "*   Librairies Tensorflow et Keras pour utiliser des réseaux de neurones.\n",
    "*   Plusieurs jeux de données et modèles de réseaux de neurones existants.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KgqsHdBYtrOQ"
   },
   "source": [
    "## Fonctionnement du notebook\n",
    "\n",
    "Un environnement d'execution dans une machine virtuelle / container, avec une interface Web pour interagir :\n",
    "\n",
    "*   Presentation (MarkDown)\n",
    "*   Code Source : ici Python\n",
    "*   Terminal\n",
    "\n",
    "cf. [Jupyter notebook](https://jupyter.org/) \n",
    "Essayer Jupyter sous différentes formes : [classique, jupyter lab, C++, R, Julia, Ruby, Scheme.](https://jupyter.org/try)\n",
    "\n",
    "Les [commandes de bases](https://jupyter.org/documentation) (Documentation)\n",
    "\n",
    "Dans le menu : Execution > Modifier le type d'execution\n",
    "\n",
    "\n",
    "*   Type d'execution : Python 3\n",
    "*   Accélérateur matériel : GPU\n",
    "\n",
    "[GPU Tesla T4](https://www.nvidia.com/fr-fr/data-center/tesla-t4/)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "hvQq4xHw0I_A",
    "outputId": "675a04f3-cf39-4524-a638-23690956386d"
   },
   "outputs": [],
   "source": [
    "!uname -a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "YrBLQaxYtmeu",
    "outputId": "051ecaac-8454-4089-8ac9-903b346d6056"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N42p7pF2fKT4"
   },
   "source": [
    "## Etape 0 : import des différentes librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JjW3C3SdTLAP"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "#CODE A COMPLETER - #importer la librairie Keras pour se servir du réseau ResNet. Documentation sur le site de Keras\n",
    "\n",
    "# FIN\n",
    "\n",
    "from tensorflow.python.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(1)\n",
    "\n",
    "\n",
    "tf.set_random_seed(1234)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K98naCq455yZ"
   },
   "source": [
    "# Exercice 1 - Rural / Urbain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gZkh0f6u_cxi"
   },
   "source": [
    "## Etape 1: importer les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "LrQaieZgjyLF",
    "outputId": "53b0072e-37b7-464b-c39d-a25378e33f8c"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/rbardon/atelier.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "rOJAC23H7bTP",
    "outputId": "031c556d-43c8-4d6c-874b-57cefba4d9a3"
   },
   "outputs": [],
   "source": [
    "%cd ./atelier/ex1 - urban & rural\n",
    "\n",
    "!unzip rural_and_urban_photos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pz-bHGR8_rq_"
   },
   "source": [
    "## Etape 2: visualiser les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 546
    },
    "colab_type": "code",
    "id": "LuV8BaP8DgJy",
    "outputId": "6b8b01f0-168f-4318-976c-7078d3220435"
   },
   "outputs": [],
   "source": [
    "im_liste_rural = [1, 14, 26, 39]\n",
    "im_liste_urban = [11, 24, 36, 43]\n",
    "\n",
    "\n",
    "#pour voir les données de type \"rural\"\n",
    "plt.figure(figsize=(18,18))\n",
    "for i in range(0,4):\n",
    "  plt.subplot(1,4,i+1)\n",
    "  plt.imshow(mpimg.imread('./train/rural/rural' + str(im_liste_rural[i]) + '.jpeg'))\n",
    "  plt.title('Rural')\n",
    "  plt.axis('off')\n",
    "  \n",
    "#pour voir les données de type \"urban\"\n",
    "plt.figure(figsize=(18,18))  \n",
    "for i in range(0,4):\n",
    "  plt.subplot(1,4,i+1)\n",
    "  plt.imshow(mpimg.imread('./train/urban/urban_' + str(im_liste_urban[i]) + '.jpeg'))\n",
    "  plt.title('Urban')\n",
    "  plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wS5-SQq1AcW1"
   },
   "source": [
    "## Etape 3: un premier modèle avec convolution\n",
    "Reseau de neurone convolutionnel ou convNet ou CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kdv46sOWgtgK"
   },
   "source": [
    "## La convolution et le transfer learning\n",
    "\n",
    "Voici ce qu'un réseau de convolution apprend et \"voit\":\n",
    "\n",
    "https://miro.medium.com/max/1400/1*jPCEik198_CjtmSL2H6o4g.png\n",
    "<img src=\"Im1.png\" style=\"width:600px;height:300px;\">\n",
    "\n",
    "Les couches initiales du réseau apprennent à détecter les formes et contours simples. La complexité des éléments qu'apprend le réseau augmente au fur et à mesure que l'on avance dans les couches successives.\n",
    "\n",
    "On peut donc en théorie (et en pratique!) utiliser un réseau ayant été entraîné sur un jeu de données et le réutiliser sur d'autres données pour répondre à une autre problématique. En effet, si les couches finales du réseau détectent des éléments très différents de notre problématique, on peut se servir d'une bonne partie du réseau qui lui détecte des formes plus ou moins génériques.\n",
    "\n",
    "Ceci a deux avantages:\n",
    "1. Partir d'un modèle déjà pré-entraîné avec de très nombreuses données et avec des capacités de calculs énormes (dont nous ne disponsons généralement pas). Ces modèles existent et ont généralement été entraînés sur des jeux de données de références (comme ImageNet)\n",
    "2. Cette approche réduit considérablement le nombre d'image nécessaires pour notre nouveau problème, car il ne reste plus qu'à \"spécialiser\" le réseau à notre nouveau problème"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qA2OEHO6MaOJ"
   },
   "source": [
    "Pour en apprendre plus sur l'utilisation classique des filtres : [https://perso.esiee.fr/~perretb/I5FM/TAI/convolution/index.html](https://perso.esiee.fr/~perretb/I5FM/TAI/convolution/index.html)\n",
    "\n",
    "et de leur utilisation en Deep Learning : [A guide to convolution arithmetic for deep learning\n",
    "](https://arxiv.org/abs/1603.07285)\n",
    "\n",
    "![Convolution : exemple de calcul](https://perso.esiee.fr/~perretb/I5FM/TAI/_images/conv2.png)\n",
    "![Un exemple de convolution](https://github.com/vdumoulin/conv_arithmetic/blob/master/gif/same_padding_no_strides.gif?raw=true)\n",
    "source : [https://github.com/vdumoulin/conv_arithmetic](https://github.com/vdumoulin/conv_arithmetic)\n",
    "\n",
    "\"kernel/noyau\", \"step\" ou \"stride/decallage\", \"padding\", \"dilated (kernel)\", \"transposed\" => upsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XwRwy4EtHxsz"
   },
   "outputs": [],
   "source": [
    "#les paramètres de base\n",
    "image_size = 224\n",
    "num_classes = 2\n",
    "batch_size_ex1 = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "WtP4XS3T_xvv",
    "outputId": "64e21cb2-1d3f-46e6-d898-1068f928690b"
   },
   "outputs": [],
   "source": [
    "#nous allons utiliser un générateur\n",
    "\n",
    "data_generator_ex1b = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "#CODE A COMPLETER\n",
    "train_generator_ex1b = data_generator_ex1b.flow_from_directory(#code à compléter ici)\n",
    "\n",
    "validation_generator_ex1b = data_generator_ex1b.flow_from_directory(#code à compléter ici)\n",
    "\n",
    "#FIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 635
    },
    "colab_type": "code",
    "id": "mytmANvkAnsn",
    "outputId": "95aa0584-0754-4c60-b03f-daa7286fa85e"
   },
   "outputs": [],
   "source": [
    "# un CNN assez simple\n",
    "init_ex1b = initializers.RandomNormal(mean=0.0, stddev=0.05, seed=1)\n",
    "\n",
    "model_ex1b = tf.keras.Sequential([\n",
    "    layers.Conv2D(32,(3,3),activation='relu',input_shape=(224,224,3), kernel_initializer= init_ex1b),\n",
    "    layers.MaxPool2D((2,2)),\n",
    "    layers.Conv2D(64,(3,3),activation='relu', kernel_initializer= init_ex1b),\n",
    "    layers.MaxPool2D((2,2)),\n",
    "    layers.Conv2D(128,(3,3),activation='relu', kernel_initializer= init_ex1b),\n",
    "    layers.MaxPool2D((2,2)),\n",
    "    layers.Conv2D(128,(3,3),activation='relu',kernel_initializer= init_ex1b),\n",
    "    layers.MaxPool2D((2,2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512,activation='relu', kernel_initializer= init_ex1b),\n",
    "    layers.Dense(num_classes, activation='softmax')   \n",
    "])\n",
    "model_ex1b.summary()\n",
    "\n",
    "model_ex1b.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 721
    },
    "colab_type": "code",
    "id": "vcQ8nxtqApwE",
    "outputId": "a2297f67-20b1-47e3-f8f4-045f827496d3"
   },
   "outputs": [],
   "source": [
    "#CODE A COMPLETER\n",
    "\n",
    "history_ex1b = model_ex1b.fit_generator(#code à compléter ici)\n",
    "\n",
    "#FIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 644
    },
    "colab_type": "code",
    "id": "7ImE7X9VIYdC",
    "outputId": "e5ffc9c2-b3cb-4639-dc44-4cfd508f2b5c"
   },
   "outputs": [],
   "source": [
    "plt.plot(history_ex1b.history['loss'])\n",
    "plt.plot(history_ex1b.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'cv'], loc='upper left')\n",
    "plt.show()\n",
    "plt.plot(history_ex1b.history['acc'])\n",
    "plt.plot(history_ex1b.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'cv'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "loss_ex1b_train, accuracy_ex1b_train = model_ex1b.evaluate_generator(train_generator_ex1b, verbose=0)\n",
    "print('Accuracy sur training: %f' % (accuracy_ex1b_train))\n",
    "print('Loss sur training: %f' % (loss_ex1b_train))\n",
    "\n",
    "loss_ex1b_val, accuracy_ex1b_val = model_ex1b.evaluate_generator(validation_generator_ex1b, verbose=0)\n",
    "print('Accuracy sur validation: %f' % (accuracy_ex1b_val))\n",
    "print('Loss sur validation: %f' % (loss_ex1b_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NLLTS7uDJH8F"
   },
   "source": [
    "## Etape 3: transfer learning\n",
    "\n",
    "Les étapes à réaliser pour du transfer learning sont les suivantes:\n",
    "\n",
    "1. Charger la base du modèle et ses poids, sans charger la \"tête\" du réseau\n",
    "\n",
    "2. Définir la \"tête\" du modèle. A minima un classificateur avec le nombre de classes de notre problème\n",
    "\n",
    "3. On fait tourner le modèle avec la base figée (i.e. trainable = false) pour que les paramètres de notre \"tête\" commencent à être affinés. Etape parfois facultative mais qui peut permettre d'éviter de diverger\n",
    "\n",
    "4. On peaufine notre modèle si nécessaire en \"relâchant\" les dernières couches de notre base (i.e. trainable = true), afin de spécialiser notre réseau sur notre jeu de données. Un compromis à trouver entre précision et temps de calcul (\"fine-tunning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "41EAV9RiJQJw",
    "outputId": "10addff1-e3ce-4d08-85c1-22deb549a5da"
   },
   "outputs": [],
   "source": [
    "data_generator_ex1tl = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator_ex1tl = data_generator_ex1tl.flow_from_directory(\n",
    "        'train',\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=batch_size_ex1,\n",
    "        class_mode='categorical',\n",
    "        seed = 1)\n",
    "\n",
    "validation_generator_ex1tl = data_generator_ex1tl.flow_from_directory(\n",
    "        'val',\n",
    "        target_size=(image_size, image_size),\n",
    "        class_mode='categorical',\n",
    "        seed = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "colab_type": "code",
    "id": "v2p_PuAeJp-I",
    "outputId": "f6289ff7-ca01-4880-caac-8aa69375c3c8"
   },
   "outputs": [],
   "source": [
    "# creation d'un nouveau modèle vide. Ajout séquentiel de couches\n",
    "model_ex1tl = Sequential()\n",
    "#n'inclue pas la dernière couche du réseau. A priori on ne veut jamais enlever plus de couches\n",
    "model_ex1tl.add(ResNet50(include_top=False, pooling='avg', weights='imagenet'))\n",
    "\n",
    "# CODE A COMPLETER pour terminer le modèle: # on ajouter un layer de fin softmax\n",
    "\n",
    "# FIN\n",
    "\n",
    "# Say not to train first layer (ResNet) model. It is already trained\n",
    "model_ex1tl.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0GN3yp2oVNma"
   },
   "source": [
    "Type de calcul d'erreur\n",
    "\n",
    "*   for binary_crossentropy: sigmoid activation, scalar target\n",
    "*   for categorical_crossentropy: softmax activation, one-hot encoded target\n",
    "\n",
    "Types de classification \n",
    "\n",
    "*   binary classification (two target classes)\n",
    "*   multi-class classification (more than two exclusive targets)\n",
    "*   multi-label classification (more than two non exclusive targets) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oMIdwV6AJ4O6"
   },
   "outputs": [],
   "source": [
    "#opt = SGD(lr=0.005, momentum=0.9)\n",
    "model_ex1tl.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy']) # categorical_crossentropy  'sgd' ou 'Adam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "colab_type": "code",
    "id": "wUqL3fmbJ_Fy",
    "outputId": "6dc449bf-0a20-4ce3-c036-bf3fe118c670"
   },
   "outputs": [],
   "source": [
    "history_ex1tl = model_ex1tl.fit_generator(\n",
    "        train_generator_ex1tl,\n",
    "        epochs=10,\n",
    "        steps_per_epoch=train_generator_ex1tl.n/batch_size_ex1,\n",
    "        validation_data=validation_generator_ex1tl,\n",
    "        validation_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 644
    },
    "colab_type": "code",
    "id": "t2wtui9OLXq-",
    "outputId": "68a3d93e-8870-40e9-b7fa-69075b3fd766"
   },
   "outputs": [],
   "source": [
    "plt.plot(history_ex1tl.history['loss'])\n",
    "plt.plot(history_ex1tl.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'cv'], loc='upper left')\n",
    "plt.show()\n",
    "plt.plot(history_ex1tl.history['acc'])\n",
    "plt.plot(history_ex1tl.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'cv'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "loss_ex1tl_train, accuracy_ex1tl_train = model_ex1tl.evaluate_generator(train_generator_ex1tl, verbose=0)\n",
    "print('Accuracy sur training: %f' % (accuracy_ex1tl_train))\n",
    "print('Loss sur training: %f' % (loss_ex1tl_train))\n",
    "\n",
    "loss_ex1tl_train, accuracy_ex1tl_train = model_ex1tl.evaluate_generator(validation_generator_ex1tl, verbose=0)\n",
    "print('Accuracy sur validation: %f' % (accuracy_ex1tl_train))\n",
    "print('Loss sur validation: %f' % (loss_ex1tl_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qXKRFeQC6D_J"
   },
   "source": [
    "# Exercice 2 - Cracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DhbJqN4lez60"
   },
   "source": [
    "## Etape 1: importer les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "n_hPUkfUPy1w",
    "outputId": "9f8000d6-b0de-4e2b-a22f-2638a0bcc598"
   },
   "outputs": [],
   "source": [
    "#CODE A COMPLETER\n",
    "\n",
    "#Changez le répertoire et dézippez le fichier pour télécharger les données\n",
    "\n",
    "# FIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7hvLAuI_ffG-"
   },
   "source": [
    "## Etape 2: visualiser les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 546
    },
    "colab_type": "code",
    "id": "Hz2erjh5THah",
    "outputId": "2db60911-76e4-4829-a86f-2f6d654e986b"
   },
   "outputs": [],
   "source": [
    "im_liste_crack = [1, 408, 894, 1136]\n",
    "im_liste_nocrack = [436, 725, 1124, 1238]\n",
    "\n",
    "\n",
    "#CODE A COMPLETER\n",
    "\n",
    "#Visualisez les données des listes crack et no crack définies ci-dessus\n",
    "\n",
    "# FIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g_8ZKKHkf3IX"
   },
   "source": [
    "## Etape 3: un premier modèle avec convolution\n",
    "Reseau de neurone convolutionnel ou convNet ou CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ku_tdUBQIAqg"
   },
   "outputs": [],
   "source": [
    "image_size = 224\n",
    "num_classes = 2 # \"crack\" ou \"no crack\" \n",
    "batch_size_ex2b = 24 # traitement des images par lot de 24 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "YpZzs2opS4Sh",
    "outputId": "7d377792-4887-4542-fd22-d39fee0bc2a3"
   },
   "outputs": [],
   "source": [
    "#nous allons utiliser un générateur\n",
    "\n",
    "data_generator_ex2b = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "train_generator_ex2b = data_generator_ex2b.flow_from_directory(\n",
    "        'train',\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=batch_size_ex2b,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator_ex2b = data_generator_ex2b.flow_from_directory(\n",
    "        'val',\n",
    "        target_size=(image_size, image_size),\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "colab_type": "code",
    "id": "3i6yzv8jTJC4",
    "outputId": "97fdaa56-3f9a-427b-b555-24f8b50a797e"
   },
   "outputs": [],
   "source": [
    "model_ex2b = tf.keras.Sequential([\n",
    "    layers.Conv2D(32,(3,3),activation='relu',input_shape=(224,224,3)),\n",
    "    layers.MaxPool2D((2,2)),\n",
    "    layers.Conv2D(64,(3,3),activation='relu'),\n",
    "    layers.MaxPool2D((2,2)),\n",
    "    layers.Conv2D(128,(3,3),activation='relu'),\n",
    "    layers.MaxPool2D((2,2)),\n",
    "    layers.Conv2D(128,(3,3),activation='relu'),\n",
    "    layers.MaxPool2D((2,2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512,activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')   \n",
    "])\n",
    "model_ex2b.summary()\n",
    "model_ex2b.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "colab_type": "code",
    "id": "rESvcPsoTqYR",
    "outputId": "ef308e09-edff-4b80-a623-65138a8c9e7c"
   },
   "outputs": [],
   "source": [
    "history_ex2b = model_ex2b.fit_generator(\n",
    "        train_generator_ex2b,\n",
    "        epochs=10,\n",
    "        steps_per_epoch=train_generator_ex2b.n/batch_size_ex2,\n",
    "        validation_data=validation_generator_ex2b,\n",
    "        validation_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 644
    },
    "colab_type": "code",
    "id": "ConE3zUxTsao",
    "outputId": "cf478807-c2fc-4997-88ea-f91b3f74f778"
   },
   "outputs": [],
   "source": [
    "plt.plot(history_ex2b.history['loss'])\n",
    "plt.plot(history_ex2b.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'cv'], loc='upper left')\n",
    "plt.show()\n",
    "plt.plot(history_ex2b.history['acc'])\n",
    "plt.plot(history_ex2b.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'cv'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "loss_ex2b_train, accuracy_ex2b_train = model_ex2b.evaluate_generator(train_generator_ex2b, verbose=0)\n",
    "print('Accuracy sur training: %f' % (accuracy_ex2b_train))\n",
    "print('Loss sur training: %f' % (loss_ex2b_train))\n",
    "\n",
    "loss_ex2b_val, accuracy_ex2b_val = model_ex2b.evaluate_generator(validation_generator_ex2b, verbose=0)\n",
    "print('Accuracy sur validation: %f' % (accuracy_ex2b_val))\n",
    "print('Loss sur validation: %f' % (loss_ex2b_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QVxcIfiqgpjb"
   },
   "source": [
    "## Etape 4 : principe de fonctionnement du transfer learning\n",
    "\n",
    "Les étapes à réaliser pour du transfer learning sont les suivantes:\n",
    "\n",
    "1. Charger la base du modèle et ses poids, sans charger la \"tête\" du réseau\n",
    "\n",
    "2. Définir la \"tête\" du modèle. A minima un classificateur avec le nombre de classes de notre problème\n",
    "\n",
    "3. On fait tourner le modèle avec la base figée (i.e. trainable = false) pour que les paramètres de notre \"tête\" commencent à être affinés. Etape parfois facultative mais qui peut permettre d'éviter de diverger\n",
    "\n",
    "4. On peaufine notre modèle si nécessaire en \"relâchant\" les dernières couches de notre base (i.e. trainable = true), afin de spécialiser notre réseau sur notre jeu de données. Un compromis à trouver entre précision et temps de calcul (\"fine-tunning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "62p2H_USIEk1"
   },
   "outputs": [],
   "source": [
    "batch_size_ex2tl = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "0uFOkK9kWJFv",
    "outputId": "65abc174-a80c-4d96-fc78-9ec0498914e8"
   },
   "outputs": [],
   "source": [
    "data_generator_ex2tl = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator_ex2tl = data_generator_ex2tl.flow_from_directory(\n",
    "        'train',\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=batch_size_ex2tl,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator_ex2tl = data_generator_ex2tl.flow_from_directory(\n",
    "        'val',\n",
    "        target_size=(image_size, image_size),\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "colab_type": "code",
    "id": "emOttJ6-WKuj",
    "outputId": "b3d628e9-1bb1-4bac-bdf8-3a52a7ceb4dc"
   },
   "outputs": [],
   "source": [
    "# creation d'un nouveau modèle vide. Ajout séquentiel de couches\n",
    "model_ex2tl = Sequential()\n",
    "#n'inclue pas la dernière couche du réseau. A priori on ne veut jamais enlever plus de couches\n",
    "model_ex2tl.add(ResNet50(include_top=False, pooling='avg', weights='imagenet'))\n",
    "# on ajouet une  (softmax: pourcentage de certitude sur des classes)\n",
    "model_ex2tl.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Say not to train first layer (ResNet) model. It is already trained\n",
    "model_ex2tl.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C-9qojkHVRpZ"
   },
   "source": [
    "Type de calcul d'erreur\n",
    "\n",
    "*   for binary_crossentropy: sigmoid activation, scalar target\n",
    "*   for categorical_crossentropy: softmax activation, one-hot encoded target\n",
    "\n",
    "Types de classification \n",
    "\n",
    "*   binary classification (two target classes)\n",
    "*   multi-class classification (more than two exclusive targets)\n",
    "*   multi-label classification (more than two non exclusive targets) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5iq_JXHaWMg5"
   },
   "outputs": [],
   "source": [
    "#opt = SGD(lr=0.005, momentum=0.9)\n",
    "model_ex2tl.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy']) # categorical_crossentropy  'sgd' ou 'Adam'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "colab_type": "code",
    "id": "6vxd7lVFWOSf",
    "outputId": "44079430-46e3-467f-9859-ccad9b58b587"
   },
   "outputs": [],
   "source": [
    "history_ex2tl = model_ex2tl.fit_generator(\n",
    "        train_generator_ex2tl,\n",
    "        epochs=6, \n",
    "        steps_per_epoch=train_generator_ex2tl.n/batch_size_ex2tl,\n",
    "        validation_data=validation_generator_ex2tl,\n",
    "        validation_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 644
    },
    "colab_type": "code",
    "id": "FiKSWwGRWQwD",
    "outputId": "136ca57e-1d8d-4c7b-ce77-57a24cf5d792"
   },
   "outputs": [],
   "source": [
    "plt.plot(history_ex2tl.history['loss'])\n",
    "plt.plot(history_ex2tl.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'cv'], loc='upper left')\n",
    "plt.show()\n",
    "plt.plot(history_ex2tl.history['acc'])\n",
    "plt.plot(history_ex2tl.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'cv'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "loss_ex2tl_train, accuracy_ex2tl_train = model_ex2tl.evaluate_generator(train_generator_ex2tl, verbose=0)\n",
    "print('Accuracy sur training: %f' % (accuracy_ex2tl_train))\n",
    "print('Loss sur training: %f' % (loss_ex2tl_train))\n",
    "\n",
    "loss_ex2tl_val, accuracy_ex2tl_val = model_ex2tl.evaluate_generator(validation_generator_ex2tl, verbose=0)\n",
    "print('Accuracy sur validation: %f' % (accuracy_ex2tl_val))\n",
    "print('Loss sur validation: %f' % (loss_ex2tl_val))\n",
    "\n",
    "# https://keras.io/getting-started/faq/#why-is-the-training-loss-much-higher-than-the-testing-loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Etape 6 : amélioration du modèle et modifications de quelques hyperparameters \n",
    "\n",
    "#Créez un modèle en rajoutant des layers à la \"tête\" (dense) chacun suivi de dropout (voir doc).\n",
    "#Essayez de réduire la taille des batch\n",
    "\n",
    "model_ex2tl2 = Sequential()\n",
    "model_ex2tl2.add(ResNet50(include_top=False, pooling='avg', weights='imagenet'))\n",
    "\n",
    "#CODE A COMPLETER\n",
    "\n",
    "#FIN\n",
    "\n",
    "# Say not to train first layer (ResNet) model. It is already trained\n",
    "model_ex2tl2.layers[0].trainable = False\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CODE A COMPLETER\n",
    "\n",
    "batch_size_ex2tl = \n",
    "\n",
    "#FIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_ex2tl2 = model_ex2tl2.fit_generator(\n",
    "        train_generator_ex2tl,\n",
    "        epochs=6, \n",
    "        steps_per_epoch=train_generator_ex2tl.n/batch_size_ex2tl,\n",
    "        validation_data=validation_generator_ex2tl,\n",
    "        validation_steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_ex2tl2.history['loss'])\n",
    "plt.plot(history_ex2tl2.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'cv'], loc='upper left')\n",
    "plt.show()\n",
    "plt.plot(history_ex2tl2.history['acc'])\n",
    "plt.plot(history_ex2tl2.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'cv'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "loss_ex2tl2_train, accuracy_ex2tl2_train = model_ex2tl2.evaluate_generator(train_generator_ex2tl, verbose=0)\n",
    "print('Accuracy sur training: %f' % (accuracy_ex2tl2_train))\n",
    "print('Loss sur training: %f' % (loss_ex2tl2_train))\n",
    "\n",
    "loss_ex2tl2_val, accuracy_ex2tl2_val = model_ex2tl2.evaluate_generator(validation_generator_ex2tl, verbose=0)\n",
    "print('Accuracy sur validation: %f' % (accuracy_ex2tl_val))\n",
    "print('Loss sur validation: %f' % (loss_ex2tl_val))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "pz-bHGR8_rq_",
    "7hvLAuI_ffG-",
    "g_8ZKKHkf3IX"
   ],
   "name": "Atelier Google.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
