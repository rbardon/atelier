{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Atelier Google - à compléter.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rbardon/atelier/blob/master/Atelier_Google_%C3%A0_compl%C3%A9ter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8byKSDweife",
        "colab_type": "text"
      },
      "source": [
        "# Développer pour l'IA : computer vision avec Transfer Learning\n",
        "\n",
        "Atelier du 23 juillet 2019 Google Atelier Numérique\n",
        "\n",
        "Animé par [Romain Bardon](https://www.linkedin.com/in/romain-bardon/) (IAdvance) et [Nicolas Lecointe](https://www.linkedin.com/in/nicolaslecointe/) (Macaron Software)\n",
        "\n",
        "\n",
        "**Objectif**: suite à notre conférence \"Intelligence Artificielle: savoir quand et comment l'utiliser pour vos projets\" du 12 juillet à Google Atelier Numérique, nous voulons montrer ici les outils qui existent pour illustrer que la technologie du Deep Learning reste relativement accessible\n",
        "\n",
        "Ce que l'on va utiliser : \n",
        "*   Librairies Tensorflow et Keras pour utiliser des réseaux de neurones.\n",
        "*   Plusieurs jeux de données et modèles de réseaux de neurones existants."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgqsHdBYtrOQ",
        "colab_type": "text"
      },
      "source": [
        "# Fonctionnement du notebook\n",
        "\n",
        "Un environnement d'execution dans une machine virtuelle / container, avec une interface Web pour interagir :\n",
        "\n",
        "*   Presentation (MarkDown)\n",
        "*   Code Source : ici Python\n",
        "*   Terminal\n",
        "\n",
        "cf. [Jupyter notebook](https://jupyter.org/) \n",
        "Essayer Jupyter sous différentes formes : [classique, jupyter lab, C++, R, Julia, Ruby, Scheme.](https://jupyter.org/try)\n",
        "\n",
        "Les [commandes de bases](https://jupyter.org/documentation) (Documentation)\n",
        "\n",
        "Dans le menu : Execution > Modifier le type d'execution\n",
        "\n",
        "\n",
        "*   Type d'execution : Python 3\n",
        "*   Accélérateur matériel : GPU\n",
        "\n",
        "[GPU Tesla T4](https://www.nvidia.com/fr-fr/data-center/tesla-t4/)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvQq4xHw0I_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!uname -a\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrBLQaxYtmeu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qA2OEHO6MaOJ",
        "colab_type": "text"
      },
      "source": [
        "# Quelques bases d'IA: la convolution et le transfer learning\n",
        "\n",
        "## La convolution\n",
        "\n",
        "Pour en apprendre plus sur l'utilisation classique des filtres : [https://perso.esiee.fr/~perretb/I5FM/TAI/convolution/index.html](https://perso.esiee.fr/~perretb/I5FM/TAI/convolution/index.html)\n",
        "\n",
        "et de leur utilisation en Deep Learning : [A guide to convolution arithmetic for deep learning\n",
        "](https://arxiv.org/abs/1603.07285)\n",
        "\n",
        "![Convolution : exemple de calcul](https://perso.esiee.fr/~perretb/I5FM/TAI/_images/conv2.png)\n",
        "![Un exemple de convolution](https://github.com/vdumoulin/conv_arithmetic/blob/master/gif/same_padding_no_strides.gif?raw=true)\n",
        "source : [https://github.com/vdumoulin/conv_arithmetic](https://github.com/vdumoulin/conv_arithmetic)\n",
        "\n",
        "\"kernel/noyau\", \"step\" ou \"stride/decallage\", \"padding\", \"dilated (kernel)\", \"transposed\" => upsample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kdv46sOWgtgK",
        "colab_type": "text"
      },
      "source": [
        "Voici ce qu'un réseau de convolution apprend et \"voit\":\n",
        "\n",
        "![Convolution : exemple de ce qu'il voit](https://blogs.nvidia.com/wp-content/uploads/2018/09/autos.png)\n",
        "\n",
        "Les couches initiales du réseau apprennent à détecter les formes et contours simples. La complexité des éléments qu'apprend le réseau augmente au fur et à mesure que l'on avance dans les couches successives.\n",
        "\n",
        "On peut donc en théorie (et en pratique!) utiliser un réseau ayant été entraîné sur un jeu de données et le réutiliser sur d'autres données pour répondre à une autre problématique. En effet, si les couches finales du réseau détectent des éléments très différents de notre problématique, on peut se servir d'une bonne partie du réseau qui lui détecte des formes plus ou moins génériques.\n",
        "\n",
        "Ceci a deux avantages:\n",
        "1. Partir d'un modèle déjà pré-entraîné avec de très nombreuses données et avec des capacités de calculs énormes (dont nous ne disponsons généralement pas). Ces modèles existent et ont généralement été entraînés sur des jeux de données de références (comme ImageNet)\n",
        "2. Cette approche réduit considérablement le nombre d'image nécessaires pour notre nouveau problème, car il ne reste plus qu'à \"spécialiser\" le réseau à notre nouveau problème"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fsiGYoIwUU9",
        "colab_type": "text"
      },
      "source": [
        "## ResNet pour du transfer learning\n",
        "\n",
        "[ResNet](https://arxiv.org/abs/1512.03385) est un réseau profond qui a gagné en 2015 le ILSVRC 2015 (ImageNet Large Scale Visual Recognition Challenge), utilisant un bloc \"identité\" pour réduire le problème du \"vanishing gradient\" (ie les valeurs des dérivés sont tellement petites que le réseau n'apprend plus):\n",
        "\n",
        "\n",
        "<img src=\"https://neurohive.io/wp-content/uploads/2019/01/resnet-e1548261477164.png\" width=\"400\">\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/1400/1*aq0q7gCvuNUqnMHh4cpnIw.png\" width=\"800\">\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/1000/1*2ns4ota94je5gSVjrpFq3A.png\" width=\"400\">\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N42p7pF2fKT4",
        "colab_type": "text"
      },
      "source": [
        "# Etape 0 : import des différentes librairies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjW3C3SdTLAP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense, Dropout, Flatten, GlobalAveragePooling2D\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras import initializers\n",
        "\n",
        "#CODE A COMPLETER - #importer la librairie Keras pour se servir du réseau ResNet. Documentation sur le site de Keras\n",
        "\n",
        "# FIN\n",
        "\n",
        "\n",
        "from tensorflow.python.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "#import os\n",
        "#os.environ['PYTHONHASHSEED']=str(1)\n",
        "\n",
        "\n",
        "#tf.set_random_seed(1234)\n",
        "#np.random.seed(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K98naCq455yZ",
        "colab_type": "text"
      },
      "source": [
        "# Exercice 1 - Rural / Urbain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZkh0f6u_cxi",
        "colab_type": "text"
      },
      "source": [
        "## Etape 1: importer les données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrQaieZgjyLF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/rbardon/atelier.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOJAC23H7bTP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd ./atelier/ex1 - urban & rural\n",
        "\n",
        "!unzip rural_and_urban_photos"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pz-bHGR8_rq_",
        "colab_type": "text"
      },
      "source": [
        "## Etape 2: visualiser les données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuV8BaP8DgJy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "im_liste_rural = [1, 14, 26, 39]\n",
        "im_liste_urban = [11, 24, 36, 43]\n",
        "\n",
        "\n",
        "#pour voir les données de type \"rural\"\n",
        "plt.figure(figsize=(18,18))\n",
        "for i in range(0,4):\n",
        "  plt.subplot(1,4,i+1)\n",
        "  plt.imshow(mpimg.imread('./train/rural/rural' + str(im_liste_rural[i]) + '.jpeg'))\n",
        "  plt.title('Rural')\n",
        "  plt.axis('off')\n",
        "  \n",
        "#pour voir les données de type \"urban\"\n",
        "plt.figure(figsize=(18,18))  \n",
        "for i in range(0,4):\n",
        "  plt.subplot(1,4,i+1)\n",
        "  plt.imshow(mpimg.imread('./train/urban/urban_' + str(im_liste_urban[i]) + '.jpeg'))\n",
        "  plt.title('Urban')\n",
        "  plt.axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wS5-SQq1AcW1",
        "colab_type": "text"
      },
      "source": [
        "## Etape 3: un premier modèle avec convolution\n",
        "Reseau de neurone convolutionnel ou convNet ou CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwRwy4EtHxsz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#les paramètres de base\n",
        "image_size = 224\n",
        "num_classes = 2\n",
        "batch_size_ex1 = 24"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtP4XS3T_xvv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#nous allons utiliser un générateur\n",
        "\n",
        "data_generator_ex1b = ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "#CODE A COMPLETER\n",
        "train_generator_ex1b = data_generator_ex1b.flow_from_directory(#code à compléter ici)\n",
        "\n",
        "validation_generator_ex1b = data_generator_ex1b.flow_from_directory(#code à compléter ici)\n",
        "\n",
        "#FIN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mytmANvkAnsn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# un CNN assez simple\n",
        "init_ex1b = initializers.RandomNormal(mean=0.0, stddev=0.05, seed=1)\n",
        "\n",
        "model_ex1b = tf.keras.Sequential([\n",
        "    layers.Conv2D(32,(3,3),activation='relu',input_shape=(224,224,3), kernel_initializer= init_ex1b),\n",
        "    layers.MaxPool2D((2,2)),\n",
        "    layers.Conv2D(64,(3,3),activation='relu', kernel_initializer= init_ex1b),\n",
        "    layers.MaxPool2D((2,2)),\n",
        "    layers.Conv2D(128,(3,3),activation='relu', kernel_initializer= init_ex1b),\n",
        "    layers.MaxPool2D((2,2)),\n",
        "    layers.Conv2D(128,(3,3),activation='relu',kernel_initializer= init_ex1b),\n",
        "    layers.MaxPool2D((2,2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(512,activation='relu', kernel_initializer= init_ex1b),\n",
        "    layers.Dense(num_classes, activation='softmax')   \n",
        "])\n",
        "\n",
        "#commande pour voir le détail de son modèle\n",
        "model_ex1b.summary()\n",
        "\n",
        "#avec Keras on doit compiler son modèle en spécifiant l'optimizer et la fonction coût\n",
        "model_ex1b.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcQ8nxtqApwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# l'entraînement du modèle\n",
        "\n",
        "#CODE A COMPLETER\n",
        "\n",
        "history_ex1b = model_ex1b.fit_generator(#code à compléter ici)\n",
        "\n",
        "#FIN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ImE7X9VIYdC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#on visualise la courbe d'apprentissage du modèle\n",
        "\n",
        "plt.plot(history_ex1b.history['loss'])\n",
        "plt.plot(history_ex1b.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'cv'], loc='upper left')\n",
        "plt.show()\n",
        "plt.plot(history_ex1b.history['acc'])\n",
        "plt.plot(history_ex1b.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'cv'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "loss_ex1b_train, accuracy_ex1b_train = model_ex1b.evaluate_generator(train_generator_ex1b, verbose=0)\n",
        "print('Accuracy sur training: %f' % (accuracy_ex1b_train))\n",
        "print('Loss sur training: %f' % (loss_ex1b_train))\n",
        "\n",
        "loss_ex1b_val, accuracy_ex1b_val = model_ex1b.evaluate_generator(validation_generator_ex1b, verbose=0)\n",
        "print('Accuracy sur validation: %f' % (accuracy_ex1b_val))\n",
        "print('Loss sur validation: %f' % (loss_ex1b_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLLTS7uDJH8F",
        "colab_type": "text"
      },
      "source": [
        "## Etape 4: transfer learning\n",
        "\n",
        "Les étapes à réaliser pour du transfer learning sont les suivantes:\n",
        "\n",
        "1. Charger la base du modèle et ses poids, sans charger la \"tête\" du réseau\n",
        "\n",
        "2. Définir la \"tête\" du modèle. A minima un classificateur avec le nombre de classes de notre problème\n",
        "\n",
        "3. On fait tourner le modèle avec la base figée (i.e. trainable = false) pour que les paramètres de notre \"tête\" commencent à être affinés. Etape parfois facultative mais qui peut permettre d'éviter de diverger\n",
        "\n",
        "4. On peaufine notre modèle si nécessaire en \"relâchant\" les dernières couches de notre base (i.e. trainable = true), afin de spécialiser notre réseau sur notre jeu de données. Un compromis à trouver entre précision et temps de calcul (\"fine-tunning\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41EAV9RiJQJw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#nous allons utiliser un autre générateur\n",
        "\n",
        "data_generator_ex1tl = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "train_generator_ex1tl = data_generator_ex1tl.flow_from_directory(\n",
        "        'train',\n",
        "        target_size=(image_size, image_size),\n",
        "        batch_size=batch_size_ex1,\n",
        "        class_mode='categorical',\n",
        "        seed = 1)\n",
        "\n",
        "validation_generator_ex1tl = data_generator_ex1tl.flow_from_directory(\n",
        "        'val',\n",
        "        target_size=(image_size, image_size),\n",
        "        class_mode='categorical',\n",
        "        seed = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2p_PuAeJp-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creation d'un nouveau modèle vide. Ajout séquentiel de couches\n",
        "model_ex1tl = Sequential()\n",
        "#n'inclue pas la dernière couche du réseau. A priori on ne veut jamais enlever plus de couches\n",
        "model_ex1tl.add(ResNet50(include_top=False, pooling='avg', weights='imagenet'))\n",
        "model_ex1tl.add(Flatten())\n",
        "# on ajoute un softmax (pourcentage de certitude sur des classes) pour avoir notre classificateur\n",
        "\n",
        "# CODE A COMPLETER pour terminer le modèle: # on ajouter un layer de fin softmax\n",
        "\n",
        "# FIN\n",
        "\n",
        "\n",
        "# On spécifie que le ResNet est figé, il ne sera pas mis à jour à chaque itération (déjà entraîné)\n",
        "model_ex1tl.layers[0].trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GN3yp2oVNma",
        "colab_type": "text"
      },
      "source": [
        "Type de calcul d'erreur\n",
        "\n",
        "*   for binary_crossentropy: sigmoid activation, scalar target\n",
        "*   for categorical_crossentropy: softmax activation, one-hot encoded target\n",
        "\n",
        "Types de classification \n",
        "\n",
        "*   binary classification (two target classes)\n",
        "*   multi-class classification (more than two exclusive targets)\n",
        "*   multi-label classification (more than two non exclusive targets) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMIdwV6AJ4O6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#opt = SGD(lr=0.005, momentum=0.9)\n",
        "model_ex1tl.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy']) # categorical_crossentropy  'sgd' ou 'Adam'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUqL3fmbJ_Fy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history_ex1tl = model_ex1tl.fit_generator(\n",
        "        train_generator_ex1tl,\n",
        "        epochs=10,\n",
        "        steps_per_epoch=train_generator_ex1tl.n/batch_size_ex1,\n",
        "        validation_data=validation_generator_ex1tl,\n",
        "        validation_steps=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2wtui9OLXq-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#on visualise la courbe d'apprentissage du modèle\n",
        "\n",
        "plt.plot(history_ex1tl.history['loss'])\n",
        "plt.plot(history_ex1tl.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'cv'], loc='upper left')\n",
        "plt.show()\n",
        "plt.plot(history_ex1tl.history['acc'])\n",
        "plt.plot(history_ex1tl.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'cv'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "loss_ex1tl_train, accuracy_ex1tl_train = model_ex1tl.evaluate_generator(train_generator_ex1tl, verbose=0)\n",
        "print('Accuracy sur training: %f' % (accuracy_ex1tl_train))\n",
        "print('Loss sur training: %f' % (loss_ex1tl_train))\n",
        "\n",
        "loss_ex1tl_train, accuracy_ex1tl_train = model_ex1tl.evaluate_generator(validation_generator_ex1tl, verbose=0)\n",
        "print('Accuracy sur validation: %f' % (accuracy_ex1tl_train))\n",
        "print('Loss sur validation: %f' % (loss_ex1tl_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXKRFeQC6D_J",
        "colab_type": "text"
      },
      "source": [
        "# Exercice 2 - Cracks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhbJqN4lez60",
        "colab_type": "text"
      },
      "source": [
        "## Etape 1: importer les données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_hPUkfUPy1w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CODE A COMPLETER\n",
        "\n",
        "#Changez le répertoire et dézippez le fichier pour télécharger les données\n",
        "\n",
        "# FIN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hvLAuI_ffG-",
        "colab_type": "text"
      },
      "source": [
        "## Etape 2: visualiser les données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hz2erjh5THah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "im_liste_crack = [1, 408, 894, 1136]\n",
        "im_liste_nocrack = [436, 725, 1124, 1238]\n",
        "\n",
        "#CODE A COMPLETER\n",
        "\n",
        "#Visualisez les données des listes crack et no crack définies ci-dessus\n",
        "\n",
        "# FIN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_8ZKKHkf3IX",
        "colab_type": "text"
      },
      "source": [
        "## Etape 3: un premier modèle avec convolution\n",
        "Reseau de neurone convolutionnel ou convNet ou CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ku_tdUBQIAqg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_size = 224\n",
        "num_classes = 2 # \"crack\" ou \"no crack\" \n",
        "batch_size_ex2b = 24 # traitement des images par lot de 24 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpZzs2opS4Sh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# on utilise un générateur\n",
        "\n",
        "data_generator_ex2b = ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "train_generator_ex2b = data_generator_ex2b.flow_from_directory(\n",
        "        'train',\n",
        "        target_size=(image_size, image_size),\n",
        "        batch_size=batch_size_ex2b,\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator_ex2b = data_generator_ex2b.flow_from_directory(\n",
        "        'val',\n",
        "        target_size=(image_size, image_size),\n",
        "        class_mode='categorical')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3i6yzv8jTJC4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# un CNN assez simple\n",
        "\n",
        "model_ex2b = tf.keras.Sequential([\n",
        "    layers.Conv2D(32,(3,3),activation='relu',input_shape=(224,224,3)),\n",
        "    layers.MaxPool2D((2,2)),\n",
        "    layers.Conv2D(64,(3,3),activation='relu'),\n",
        "    layers.MaxPool2D((2,2)),\n",
        "    layers.Conv2D(128,(3,3),activation='relu'),\n",
        "    layers.MaxPool2D((2,2)),\n",
        "    layers.Conv2D(128,(3,3),activation='relu'),\n",
        "    layers.MaxPool2D((2,2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(512,activation='relu'),\n",
        "    layers.Dense(num_classes, activation='softmax')   \n",
        "])\n",
        "\n",
        "#commande pour voir le détail de son modèle\n",
        "model_ex2b.summary()\n",
        "\n",
        "#on compile le modèle\n",
        "model_ex2b.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rESvcPsoTqYR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# l'entraînement du modèle\n",
        "\n",
        "history_ex2b = model_ex2b.fit_generator(\n",
        "        train_generator_ex2b,\n",
        "        epochs=10,\n",
        "        steps_per_epoch=train_generator_ex2b.n/batch_size_ex2b,\n",
        "        validation_data=validation_generator_ex2b,\n",
        "        validation_steps=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ConE3zUxTsao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#on visualise la courbe d'apprentissage du modèle\n",
        "\n",
        "plt.plot(history_ex2b.history['loss'])\n",
        "plt.plot(history_ex2b.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'cv'], loc='upper left')\n",
        "plt.show()\n",
        "plt.plot(history_ex2b.history['acc'])\n",
        "plt.plot(history_ex2b.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'cv'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "loss_ex2b_train, accuracy_ex2b_train = model_ex2b.evaluate_generator(train_generator_ex2b, verbose=0)\n",
        "print('Accuracy sur training: %f' % (accuracy_ex2b_train))\n",
        "print('Loss sur training: %f' % (loss_ex2b_train))\n",
        "\n",
        "loss_ex2b_val, accuracy_ex2b_val = model_ex2b.evaluate_generator(validation_generator_ex2b, verbose=0)\n",
        "print('Accuracy sur validation: %f' % (accuracy_ex2b_val))\n",
        "print('Loss sur validation: %f' % (loss_ex2b_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVxcIfiqgpjb",
        "colab_type": "text"
      },
      "source": [
        "## Etape 4 : avec transfer learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62p2H_USIEk1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size_ex2tl = 24"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uFOkK9kWJFv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# on utilise un générateur\n",
        "data_generator_ex2tl = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "train_generator_ex2tl = data_generator_ex2tl.flow_from_directory(\n",
        "        'train',\n",
        "        target_size=(image_size, image_size),\n",
        "        batch_size=batch_size_ex2tl,\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator_ex2tl = data_generator_ex2tl.flow_from_directory(\n",
        "        'val',\n",
        "        target_size=(image_size, image_size),\n",
        "        class_mode='categorical')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emOttJ6-WKuj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creation d'un modèle\n",
        "model_ex2tl = Sequential()\n",
        "\n",
        "model_ex2tl.add(ResNet50(include_top=False, pooling='avg', weights='imagenet'))\n",
        "model_ex2tl.add(Flatten())\n",
        "model_ex2tl.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# on fige le ResNet\n",
        "model_ex2tl.layers[0].trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iq_JXHaWMg5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#on compile le modèle\n",
        "model_ex2tl.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy']) # categorical_crossentropy  'sgd' ou 'Adam'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vxd7lVFWOSf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# l'entraînement du modèle\n",
        "history_ex2tl = model_ex2tl.fit_generator(\n",
        "        train_generator_ex2tl,\n",
        "        epochs=6, \n",
        "        steps_per_epoch=train_generator_ex2tl.n/batch_size_ex2tl,\n",
        "        validation_data=validation_generator_ex2tl,\n",
        "        validation_steps=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiKSWwGRWQwD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#on visualise la courbe d'apprentissage du modèle\n",
        "\n",
        "plt.plot(history_ex2tl.history['loss'])\n",
        "plt.plot(history_ex2tl.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'cv'], loc='upper left')\n",
        "plt.show()\n",
        "plt.plot(history_ex2tl.history['acc'])\n",
        "plt.plot(history_ex2tl.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'cv'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "loss_ex2tl_train, accuracy_ex2tl_train = model_ex2tl.evaluate_generator(train_generator_ex2tl, verbose=0)\n",
        "print('Accuracy sur training: %f' % (accuracy_ex2tl_train))\n",
        "print('Loss sur training: %f' % (loss_ex2tl_train))\n",
        "\n",
        "loss_ex2tl_val, accuracy_ex2tl_val = model_ex2tl.evaluate_generator(validation_generator_ex2tl, verbose=0)\n",
        "print('Accuracy sur validation: %f' % (accuracy_ex2tl_val))\n",
        "print('Loss sur validation: %f' % (loss_ex2tl_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIk3QvXgE9iI",
        "colab_type": "text"
      },
      "source": [
        "## Etape 5: amélioration du modèle\n",
        "\n",
        "Créez un modèle en rajoutant des layers à la \"tête\" (dense) chacun suivi de dropout (voir doc).\n",
        "\n",
        "Essayez de réduire la taille des batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKCfGONiJdp3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CODE A COMPLETER\n",
        "\n",
        "batch_size_ex2tl2 = #à compléter\n",
        "\n",
        "#FIN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XlQ5V2v-v-yO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# on utilise un générateur\n",
        "data_generator_ex2tl2 = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "train_generator_ex2tl2 = data_generator_ex2tl2.flow_from_directory(\n",
        "        'train',\n",
        "        target_size=(image_size, image_size),\n",
        "        batch_size=batch_size_ex2tl2,\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator_ex2tl2 = data_generator_ex2tl2.flow_from_directory(\n",
        "        'val',\n",
        "        target_size=(image_size, image_size),\n",
        "        class_mode='categorical')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrjBGZwJO8Xl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creation d'un nouveau modèle\n",
        "model_ex2tl2 = Sequential()\n",
        "\n",
        "model_ex2tl2.add(ResNet50(include_top=False, pooling='avg', weights='imagenet'))\n",
        "model_ex2tl2.add(Flatten())\n",
        "\n",
        "#CODE A COMPLETER\n",
        "\n",
        "#Rajoutez 2 layers Dense, chacun suivi de dropout\n",
        "\n",
        "#FIN\n",
        "\n",
        "model_ex2tl2.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# on fige le ResNet\n",
        "model_ex2tl2.layers[0].trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_K9UlYMvPGNp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# on compile le modèle\n",
        "model_ex2tl2.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy']) # categorical_crossentropy  'sgd' ou 'Adam'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vb3m1wRCPIqY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# l'entraînement du modèle\n",
        "history_ex2tl2 = model_ex2tl2.fit_generator(\n",
        "        train_generator_ex2tl2,\n",
        "        epochs=6, \n",
        "        steps_per_epoch=train_generator_ex2tl2.n/batch_size_ex2tl2,\n",
        "        validation_data=validation_generator_ex2tl2,\n",
        "        validation_steps=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rfw73bm5PMtw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#on visualise la courbe d'apprentissage du modèle\n",
        "\n",
        "plt.plot(history_ex2tl2.history['loss'])\n",
        "plt.plot(history_ex2tl2.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'cv'], loc='upper left')\n",
        "plt.show()\n",
        "plt.plot(history_ex2tl2.history['acc'])\n",
        "plt.plot(history_ex2tl2.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'cv'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "loss_ex2tl2_train, accuracy_ex2tl2_train = model_ex2tl2.evaluate_generator(train_generator_ex2tl2, verbose=0)\n",
        "print('Accuracy sur training: %f' % (accuracy_ex2tl2_train))\n",
        "print('Loss sur training: %f' % (loss_ex2tl2_train))\n",
        "\n",
        "loss_ex2tl2_val, accuracy_ex2tl2_val = model_ex2tl2.evaluate_generator(validation_generator_ex2tl2, verbose=0)\n",
        "print('Accuracy sur validation: %f' % (accuracy_ex2tl2_val))\n",
        "print('Loss sur validation: %f' % (loss_ex2tl2_val))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}